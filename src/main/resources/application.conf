akka {
  loglevel = "INFO"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  extensions = [
    "kamon.metric.Metrics",
    "kamon.datadog.Datadog",
    "kamon.system.SystemMetrics",
    "kamon.logreporter.LogReporter"
  ]

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      hostname = ${?AKKA_HOSTNAME}
      port = 0
      port = ${?AKKA_PORT}
      bind-hostname = "0.0.0.0"
    }
  }

  cluster {
    seed-nodes = [
      "akka.tcp://cluster@127.0.0.1:2551"
    ]

    auto-down-unreachable-after = 10s
  }
}

akka.persistence.journal.plugin = "dynamodb-journal"

dynamodb-journal {
  journal-table =  "akka-actor-journal"
  # journal-name =  "prefixes all keys, allows multiple journals per table, default: `journal`"
  aws-access-key-id =  "yourKey"
  aws-secret-access-key =  "yourSecret"
  operation-timeout =  10 seconds
  endpoint = "https://localhost:8000"
  # endpoint =  "defaults to https://dynamodb.us-east-1.amazonaws.com"
  sequence-shards = 1000
}


kamon {
  metrics {
    filters = [
      {
        actor {
          includes = [ "user/*", "user/worker-*" ]
          excludes = [ "system/*" ]
        }
      },
      {
        trace {
          includes = [ "*" ]
          excludes = []
        }
      }
    ]
  }

  datadog {
    hostname = "127.0.0.1"
    port = 8125

    flush-interval = 1 second

    max-packet-size = 1024 bytes

    report-system-metrics = true

    includes {
      actor       = [ "*" ]
      trace       = [ "*" ]
      dispatcher  = [ "*" ]
    }

    application-name = "akka-pull"
  }

}